{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangChain ReAct Agent with Couchbase via Model Context Protocol (MCP) - A Tutorial\n",
        "\n",
        "This notebook demonstrates how to build a ReAct (Reasoning and Acting) agent using [LangChain](https://www.langchain.com/) and [LangGraph](https://www.langchain.com/langgraph) that can interact with a Couchbase database. The key to this interaction is the Model Context Protocol (MCP), which allows the AI agent to seamlessly connect to and use Couchbase as a tool. Read more about LangGraph's ReAct agent [here](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.chat_agent_executor.create_react_agent).\n",
        "\n",
        "## What is the Model Context Protocol (MCP)?\n",
        "\n",
        "The [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard designed to standardize how AI assistants and applications connect to and interact with external data sources, tools, and systems. Think of MCP as a universal adapter that allows AI models to seamlessly access the context they need to produce more relevant, accurate, and actionable responses.\n",
        "\n",
        "**Key Goals and Features of MCP:**\n",
        "\n",
        "*   **Standardized Communication:** MCP provides a common language and structure for AI models to communicate with diverse backend systems, replacing the need for numerous custom integrations.\n",
        "*   **Enhanced Context Management:** It helps manage the limited context windows of LLMs efficiently, enabling them to maintain longer, more coherent interactions and leverage historical data.\n",
        "*   **Secure Data Access:** MCP emphasizes secure connections, allowing developers to expose data through MCP servers while maintaining control over their infrastructure.\n",
        "*   **Tool Use and Actionability:** It enables LLMs to not just retrieve information but also to use external tools and trigger actions in other systems.\n",
        "*   **Interoperability:** Fosters an ecosystem where different AI tools, models, and data sources can work together more cohesively.\n",
        "\n",
        "MCP aims to break down data silos, making it easier for AI to integrate with real-world applications and enterprise systems, leading to more powerful and context-aware AI solutions.\n",
        "\n",
        "**MCP Typically Follows a Client-Server Architecture:**\n",
        "*   **MCP Hosts/Clients:** Applications (like AI assistants, IDEs, or other AI-powered tools) that want to access data or capabilities. In this demo, this notebook, through LangChain, acts as an MCP client.\n",
        "*   **MCP Servers:** Lightweight programs that expose specific data sources or tools (e.g., a database, an API) through the standardized MCP. The `mcp-server-couchbase` project fulfills this role for Couchbase.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Before you start\n",
        "## Get Credentials for OpenAI\n",
        "Please follow the [instructions](https://platform.openai.com/docs/quickstart) to generate the OpenAI credentials.\n",
        "## Create and Deploy Your Free Tier Operational cluster on Capella\n",
        "\n",
        "To get started with Couchbase Capella, create an account and use it to deploy a forever free tier operational cluster. This account provides you with an environment where you can explore and learn about Capella with no time constraint.\n",
        "\n",
        "To learn more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
        "\n",
        "### Couchbase Capella Configuration\n",
        "\n",
        "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
        "\n",
        "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the required bucket (Read and Write) used in the application.\n",
        "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running.\n",
        "* Your Capella free-tier account includes a travel-sample bucket, with sample documents used for booking and travel purposes. You can find more information [here](https://docs.couchbase.com/cloud/get-started/run-first-queries.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Instructions\n",
        "\n",
        "Before running this notebook, ensure you have the following prerequisites met:\n",
        "\n",
        "*   **`mcp-server-couchbase` Project:**\n",
        "    *   Clone the `mcp-server-couchbase` project from [here](https://github.com/Couchbase-Ecosystem/mcp-server-couchbase).\n",
        "    *   You'll need the local path to this project to start the MCP server from this notebook. **Update this path in the `StdioServerParameters` cell later if yours is different.**\n",
        "*   **Set Environment Variables:** This notebook loads the OpenAI API key and other environment variables from the `.env` file. Include the following:\n",
        "\n",
        "    ```\n",
        "    OPENAI_API_KEY=your_openai_api_key_here\n",
        "    CB_CONNECTION_STRING=your_couchbase_connection_string\n",
        "    CB_USERNAME=your_couchbase_username\n",
        "    CB_PASSWORD=your_couchbase_password\n",
        "    CB_BUCKET_NAME=your_target_bucket # e.g., travel-sample\n",
        "    ```\n",
        "\n",
        "    We have already included a `.env.sample` file. Change the file name to `.env` and fill in the environment variables.\n",
        "*   **Setup uv:** uv is a modern and fast python package and project manager. We will use uv to run the MCP server. Install uv from [here](https://docs.astral.sh/uv/getting-started/installation/#installing-uv).\n",
        "*   **Python Libraries:** Install the necessary libraries by running the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q 'langchain>=1.2.10' 'langgraph>=1.0.9' 'langchain-openai>=1.1.10' 'langchain-mcp-adapters>=0.2.1' 'python-dotenv>=1.2.1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Necessary Libraries\n",
        "\n",
        "This cell imports the essential Python tools for our project:\n",
        "\n",
        "*   **`dotenv` & `os`:** For loading and using secret API keys and other settings from a `.env` file.\n",
        "*   **`mcp` (ClientSession, StdioServerParameters, stdio_client):** For connecting this notebook (as a client) to the MCP server, which in turn talks to Couchbase.\n",
        "*   **`langchain_mcp_adapters.tools` (`load_mcp_tools`):** To make the Couchbase tools (exposed via MCP) usable by our LangChain AI agent.\n",
        "*   **`langgraph.prebuilt` (`create_react_agent`):** To easily build a \"ReAct\" AI agent that can think and use tools.\n",
        "*   **`langgraph.checkpoint.memory` (`InMemorySaver`):** To help the agent remember past parts of the conversation.\n",
        "*   **`langchain_openai` (`ChatOpenAI`):** To connect to and use OpenAI's language models (like GPT-5).\n",
        "\n",
        "Running this cell makes all these components ready to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.stdio import stdio_client\n",
        "\n",
        "from langchain_mcp_adapters.tools import load_mcp_tools\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Question-Answering Function\n",
        "\n",
        "This cell defines an asynchronous function `qna(agent)` that we'll use to interact with our ReAct agent.\n",
        "\n",
        "*   It takes the created `agent` as an argument.\n",
        "*   `config = {\"configurable\": {\"thread_id\": \"1\"}}`: This configuration is important for LangGraph agents. It uses a `thread_id` to maintain conversation state. Using the same `thread_id` across multiple calls to the agent allows it to remember previous interactions in that \"thread.\"\n",
        "*   The function then defines a series of example questions (`message`) which we want to ask the agent. The agent queries the Couchbase MCP to get travel related data, formats it and presents it to the user.\n",
        "*   This function allows us to easily test the agent with multiple queries in sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def qna(agent):\n",
        "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "    message = \"Tell me about the database that you are connected to.\"\n",
        "    print(f\"\\n\\n**Running:** {message}\\n\")\n",
        "    result = await agent.ainvoke({\"messages\": message}, config)\n",
        "    print(result[\"messages\"][-1].content)\n",
        "    print('-'*50)\n",
        "\n",
        "    message = \"List out the top 5 hotels by the highest aggregate rating?\"\n",
        "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
        "    result = await agent.ainvoke({\"messages\": message}, config)\n",
        "    print(result[\"messages\"][-1].content)\n",
        "    print('-'*50)\n",
        "\n",
        "    message = \"Recommend me a flight and hotel from New York to San Francisco\"\n",
        "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
        "    result = await agent.ainvoke({\"messages\": message}, config)\n",
        "    print(result[\"messages\"][-1].content)\n",
        "    print('-'*50)\n",
        "\n",
        "    message = \"I'm going to the UK for 1 week. Recommend some great spots to visit for sightseeing. Also mention the respective prices of those places for adults and kids.\"\n",
        "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
        "    result = await agent.ainvoke({\"messages\": message}, config)\n",
        "    print(result[\"messages\"][-1].content)\n",
        "    print('-'*50)\n",
        "\n",
        "    message = \"My budget is around 30 pounds a night. What will be the best hotel to stay in?\"\n",
        "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
        "    result = await agent.ainvoke({\"messages\": message}, config)\n",
        "    print(result[\"messages\"][-1].content)\n",
        "    print('-'*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the System Prompt\n",
        "\n",
        "The system prompt is a crucial piece of instruction given to the Large Language Model (LLM) that powers our agent. It sets the context, defines the agent's persona, capabilities, and constraints.\n",
        "\n",
        "In this system prompt:\n",
        "*   We explain the **Couchbase data hierarchy** (Cluster, Bucket, Scope, Collection, Document) to help the LLM understand how the data is organized.\n",
        "*   We specifically instruct the agent that **\"The data is inside `inventory` scope, so use only that scope.\"** This focuses the agent on the relevant part of the `travel-sample` database.\n",
        "*   We provide **SQL++ query generation guidelines**:\n",
        "    *   \"Any query you generate needs to have only the collection name in the FROM clause.\"\n",
        "    *   \"Every field, collection, scope or bucket name inside the query should be inside backticks.\"\n",
        "*   The overall goal is to guide the LLM to use the provided MCP tools (which will be Couchbase operations) effectively and to formulate correct SQL++ queries for the `inventory` scope.\n",
        "\n",
        "A well-crafted system prompt significantly improves the agent's performance and reliability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"Couchbase organizes data with the following hierarchy (from top to bottom):\n",
        "1. Cluster: The overall container of all Couchbase data and services.\n",
        "2. Bucket: A bucket is similar to a database in traditional systems. Each bucket contains multiple scopes. Example: \"users\", \"analytics\", \"products\"\n",
        "3. Scope: A scope is a namespace within a bucket that groups collections. Scopes help isolate data for different microservices or tenants. Default scope name: _default\n",
        "4. Collection: The equivalent of a table in relational databases. Collections store JSON documents. Default collection name: _default\n",
        "5. Document: The atomic data unit (usually JSON) stored in a collection. Each document has a unique key within its collection.IMPORTANT SQL++ Query Rules:\n",
        "\n",
        "- Use the tools to read the database and answer questions based on this database\n",
        "- The data is inside `inventory` scope, so use only that scope\n",
        "- Use only the collection name in the FROM clause (e.g., FROM `hotel`)\n",
        "- Collection names and top-level field names should be in backticks\n",
        "- For nested fields, use dot notation WITHOUT backticks around each part\n",
        "\n",
        "  CORRECT: `hotel`.reviews[0].ratings.Overall\n",
        "  WRONG: `hotel`.`reviews`.`ratings`.`Overall`\n",
        "\n",
        "- When accessing nested objects or arrays, use bracket notation or dot notation directly\n",
        "\n",
        "Examples:\n",
        "- hotel.reviews[0].author\n",
        "- hotel.address.city (note: address is a single object, not an array)Hotel Document Structure:\n",
        "- address: Object with fields like {city, country, address, state, county}\n",
        "- reviews: Array of review objects with ratings and content\n",
        "- To filter by city: WHERE address.city = \"San Francisco\"\n",
        "- Do NOT use \"addresses\" (plural) - the field is \"address\" (singular)ARRAY Operations in SQL++:\n",
        "- To aggregate data from arrays (like reviews), use UNNEST to flatten the array first\n",
        "- CORRECT way to sum array values:\n",
        "\n",
        "  SELECT h.name, SUM(r.ratings.Overall) as total_rating\n",
        "  FROM `hotel` h\n",
        "  UNNEST h.reviews r\n",
        "  GROUP BY h.name\n",
        "  ORDER BY total_rating DESC- WRONG ways (these will cause parser errors):\n",
        "  x SELECT name, SUM(ARRAY_SUM(ARRAY reviews[*].ratings.Overall FOR reviews IN...))\n",
        "  x SELECT name, ARRAY reviews[*].ratings.Overall FOR reviews...\n",
        "  x WHERE ANY a IN addresses SATISFIES... (wrong field name)- Use UNNEST whenever you need to work with individual array elements in aggregations\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuring the Language Model and MCP Server\n",
        "\n",
        "This cell sets up two key components:\n",
        "\n",
        "1.  **`model = ChatOpenAI(model=\"gpt-5.2\")`**: This line initializes the LLM we'll be using. We're choosing `gpt-5.2` from OpenAI.\n",
        "2.  **`server_params = StdioServerParameters(...)`**:\n",
        "    *   This configures how our Python script will start and communicate with the `mcp-server-couchbase` application.\n",
        "    *   `command=\"uv\"` and `args=[...]`: This specifies the command to run. Here, it's using `uv run` (a fast Python project and virtual environment manager) to execute the `mcp_server.py` script located in the `mcp-server-couchbase` project directory.\n",
        "        *   **IMPORTANT:** You **MUST** update the `\"--directory\"`, path to point to the correct location of your cloned `mcp-server-couchbase` repository.\n",
        "    *   `env={...}`: This dictionary defines environment variables that will be passed to the MCP server process when it starts. These are crucial for the MCP server to connect to your Couchbase instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model=\"gpt-5.2\")\n",
        "\n",
        "server_params = StdioServerParameters(\n",
        "    command=\"uv\",\n",
        "    args=[\n",
        "        \"--directory\",\n",
        "        \"/path/to/mcp-server-couchbase\",\n",
        "        \"run\",\n",
        "        \"src/mcp_server.py\"\n",
        "    ],\n",
        "    env={\n",
        "        \"CB_CONNECTION_STRING\": os.getenv(\"CB_CONNECTION_STRING\"),\n",
        "        \"CB_USERNAME\": os.getenv(\"CB_USERNAME\"),\n",
        "        \"CB_PASSWORD\": os.getenv(\"CB_PASSWORD\"),\n",
        "        \"CB_BUCKET_NAME\": os.getenv(\"CB_BUCKET_NAME\")\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Main Execution Logic\n",
        "\n",
        "The `main` function ties everything together to set up and run our agent:\n",
        "\n",
        "1.  **Start & Connect to MCP Server:** It first starts the `mcp-server-couchbase` process using `stdio_client` and establishes a communication `ClientSession` with it.\n",
        "2.  **Initialize Session & Load Tools:** The MCP `session` is initialized. Then, `load_mcp_tools` queries the MCP server to get the available Couchbase tools and prepares them for LangChain.\n",
        "3.  **Set Up Agent Memory:** `InMemorySaver` is created to allow the agent to remember conversation history.\n",
        "4.  **Create ReAct Agent:** The `create_react_agent` function builds our AI agent, providing it with the language `model`, the Couchbase `tools`, our `system_prompt`, and the `checkpoint` for memory.\n",
        "5.  **Run Q&A:** Finally, it calls the `qna` function, passing the created `agent` to start the question-and-answer process with the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def main():\n",
        "    async with stdio_client(server_params) as (read, write):\n",
        "        async with ClientSession(read, write) as session:\n",
        "            # Initialize the connection\n",
        "            print(\"Initializing connection...\")\n",
        "            await session.initialize()\n",
        "\n",
        "            # Get tools\n",
        "            print(\"Loading tools...\")\n",
        "            tools = await load_mcp_tools(session)\n",
        "\n",
        "            # Create and run the agent\n",
        "            print(\"Creating agent...\")\n",
        "            checkpoint = InMemorySaver()\n",
        "\n",
        "            agent = create_react_agent(\n",
        "                model, \n",
        "                tools,\n",
        "                prompt=system_prompt,\n",
        "                checkpointer=checkpoint\n",
        "            )\n",
        "\n",
        "            print(\"-\"*25, \"Starting Run\", \"-\"*25)\n",
        "            await qna(agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Agent\n",
        "\n",
        "This final cell simply executes the `await main()` function.\n",
        "\n",
        "When you run this cell:\n",
        "1.  The `mcp-server-couchbase` process will be started in the background.\n",
        "2.  The Python script will connect to it as an MCP client.\n",
        "3.  The LangChain ReAct agent will be initialized with the Couchbase tools exposed via MCP.\n",
        "4.  The agent will then attempt to answer the series of questions defined in the `qna` function by:\n",
        "    *   Reasoning about the question.\n",
        "    *   Deciding if a Couchbase tool is needed.\n",
        "    *   Formulating a SQL++ query (if appropriate, based on the system prompt).\n",
        "    *   Executing the tool (which sends the query to the MCP server, which then runs it on Couchbase).\n",
        "    *   Using the tool's output to generate a natural language response.\n",
        "\n",
        "You will see the questions and the agent's answers printed below. This demonstrates the end-to-end flow of a natural language query being translated into database actions and then into a user-friendly response, all orchestrated by the LangChain agent using MCP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing connection...\n",
            "Loading tools...\n",
            "Creating agent...\n",
            "------------------------- Starting Run -------------------------\n",
            "\n",
            "\n",
            "**Running:** Tell me about the database that you are connected to.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zd/hmksn4rj5kd_pj7w7bw48y9m0000gn/T/ipykernel_35842/3750795696.py:16: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  agent = create_react_agent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You’re connected to a **Couchbase** cluster with the **`travel-sample`** bucket, which is Couchbase’s standard sample dataset (travel domain: airlines, airports, routes, hotels, landmarks, plus some tenant-style data).\n",
            "\n",
            "## Connection & services\n",
            "The cluster connection and bucket connection are both **successful**.\n",
            "\n",
            "The cluster is running and responding on these Couchbase services (all healthy / `ok`), with approximate latencies:\n",
            "- **KV (data)**: ~0.4–0.5 ms\n",
            "- **Query (SQL++ / N1QL)**: ~2.1 ms\n",
            "- **Analytics**: ~4.9 ms\n",
            "- **Search (FTS)**: ~2.4 ms\n",
            "- **Views**: ~3.3 ms\n",
            "- **Management**: ~3.0 ms\n",
            "\n",
            "## Data organization in `travel-sample`\n",
            "Within the bucket, these **scopes** and **collections** are available:\n",
            "\n",
            "### Scope: `inventory`  *(main sample data)*\n",
            "- `airline`\n",
            "- `airport`\n",
            "- `hotel`\n",
            "- `landmark`\n",
            "- `route`\n",
            "\n",
            "### Scopes: `tenant_agent_00` … `tenant_agent_04`  *(multi-tenant-style examples)*\n",
            "Each contains:\n",
            "- `users`\n",
            "- `bookings`\n",
            "\n",
            "### Other scopes\n",
            "- `_default`: `_default`\n",
            "- `_system`: `_query`, `_mobile`\n",
            "\n",
            "## Important note for querying (per your rules)\n",
            "All of the primary travel dataset is inside the **`inventory`** scope, so queries should be run in that scope and use only the **collection name** in the `FROM` clause (e.g., `FROM \\`hotel\\``).\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "**Running**: List out the top 5 hotels by the highest aggregate rating?\n",
            "\n",
            "Top 5 hotels by **highest aggregate (sum) of `ratings.Overall` across all reviews**:\n",
            "\n",
            "| Rank | Hotel | Total overall rating (SUM) | Review count |\n",
            "|---:|---|---:|---:|\n",
            "| 1 | Hotel Eldorado | 109 | 29 |\n",
            "| 2 | Hafod Lon Holiday Apartment | 70 | 17 |\n",
            "| 3 | Uist Outdoor Centre | 53 | 12 |\n",
            "| 4 | Radisson Blu | 50 | 13 |\n",
            "| 5 | Lochmaddy Hotel | 50 | 11 |\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "**Running**: Recommend me a flight and hotel from New York to San Francisco\n",
            "\n",
            "Here’s a solid **flight + hotel** recommendation for a trip from **New York (NYC area) → San Francisco** based on what’s in the `travel-sample` dataset.\n",
            "\n",
            "## Flight recommendation (route exists in the database)\n",
            "- **From:** **JFK** (John F Kennedy Intl, New York)\n",
            "- **To:** **SFO** (San Francisco Intl, San Francisco)\n",
            "- **Airline:** **United Airlines (UA)**  \n",
            "  (This JFK → SFO route appears in the `route` collection; other airlines in the dataset on this route include AA, DL, B6, AS, VX, US.)\n",
            "\n",
            "## Hotel recommendation (San Francisco)\n",
            "**Hyatt Regency San Francisco**\n",
            "- In the dataset as a San Francisco hotel\n",
            "- Review stats in the dataset: **avg overall rating ~ 4.6** across **5 reviews** (from `hotel` + `UNNEST reviews`)\n",
            "\n",
            "If you tell me your travel dates and whether you prefer **cheapest**, **best-rated**, or **closest to downtown**, I can narrow it down further (and also choose SFO vs OAK vs SJC for the arrival airport).\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "**Running**: I'm going to the UK for 1 week. Recommend some great spots to visit for sightseeing. Also mention the respective prices of those places for adults and kids.\n",
            "\n",
            "I can recommend great UK sightseeing spots from the dataset I’m connected to (it includes UK **landmarks**), but it **doesn’t store admission prices** for adults/kids in the `travel-sample` data—so I can’t reliably quote ticket prices from this database.\n",
            "\n",
            "## Great UK sightseeing spots (from the dataset)\n",
            "Here are some strong, classic picks you can build a 1‑week itinerary around (London + a couple of day trips / overnights):\n",
            "\n",
            "- **Tower of London (London)** – iconic history, Crown Jewels\n",
            "- **British Museum (London)** – world-class collections\n",
            "- **Buckingham Palace (London)** – Changing of the Guard area / (seasonal) State Rooms\n",
            "- **Westminster Abbey (London)** – major royal & national site\n",
            "- **Edinburgh Castle (Edinburgh)** – top landmark in Scotland\n",
            "- **Roman Baths (Bath)** – classic historic site\n",
            "- **Stonehenge (near Salisbury)** – best-known prehistoric monument\n",
            "- **Giant’s Causeway (Northern Ireland)** – unique coastal geology (if you’re willing to fly/train+ferry)\n",
            "\n",
            "## About adult/kid prices\n",
            "To include *adult* and *child* prices accurately, I need either:\n",
            "1) permission to use current web pricing (official sites), **or**\n",
            "2) you tell me your **travel month** + which cities you’ll base in (e.g., London only vs London + Edinburgh), and I can give a “likely price range” with a clear disclaimer.\n",
            "\n",
            "### Quick questions\n",
            "1) Which areas are you visiting: **London only**, **London + Edinburgh**, or **multi-city (London/Bath/Oxford/etc.)**?\n",
            "2) How many **adults** and **kids**, and kids’ ages (many UK attractions have age brackets)?\n",
            "\n",
            "Answer those and I’ll return a tight 7‑day sightseeing plan and include adult/child pricing (either from official sources if you allow web lookup, or as ranges if not).\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "**Running**: My budget is around 30 pounds a night. What will be the best hotel to stay in?\n",
            "\n",
            "The `travel-sample` hotel data I’m connected to doesn’t include **room prices**, so I can’t determine which hotels are “best” specifically for **£30/night** from this database alone.\n",
            "\n",
            "If you still want a useful recommendation, I can do one of these:\n",
            "\n",
            "1) **Best-rated UK hotels in the dataset (by review score)** and you can then check live prices for your dates, or  \n",
            "2) If you tell me the **UK city/area** you’ll stay in (e.g., London, Edinburgh, Bath) and whether **hostels are OK**, I can recommend the most budget-appropriate *types* of places from the dataset (e.g., YHA hostels / bunkhouses), which are the most likely to hit ~£30/night.\n",
            "\n",
            "Tell me:\n",
            "- Which **city** are you basing yourself in?\n",
            "- **1 person or 2**, and is a **hostel/private room** acceptable?\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "await main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
