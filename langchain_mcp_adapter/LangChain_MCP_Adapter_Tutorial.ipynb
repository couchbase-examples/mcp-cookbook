{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain ReAct Agent with Couchbase via Model Context Protocol (MCP) - A Tutorial\n",
    "\n",
    "This notebook demonstrates how to build a ReAct (Reasoning and Acting) agent using [LangChain](https://www.langchain.com/) and [LangGraph](https://www.langchain.com/langgraph) that can interact with a Couchbase database. The key to this interaction is the Model Context Protocol (MCP), which allows the AI agent to seamlessly connect to and use Couchbase as a tool. Read more about LangGraph's ReAct agent [here](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.chat_agent_executor.create_react_agent).\n",
    "\n",
    "## What is the Model Context Protocol (MCP)?\n",
    "\n",
    "The [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard designed to standardize how AI assistants and applications connect to and interact with external data sources, tools, and systems. Think of MCP as a universal adapter that allows AI models to seamlessly access the context they need to produce more relevant, accurate, and actionable responses.\n",
    "\n",
    "**Key Goals and Features of MCP:**\n",
    "\n",
    "*   **Standardized Communication:** MCP provides a common language and structure for AI models to communicate with diverse backend systems, replacing the need for numerous custom integrations.\n",
    "*   **Enhanced Context Management:** It helps manage the limited context windows of LLMs efficiently, enabling them to maintain longer, more coherent interactions and leverage historical data.\n",
    "*   **Secure Data Access:** MCP emphasizes secure connections, allowing developers to expose data through MCP servers while maintaining control over their infrastructure.\n",
    "*   **Tool Use and Actionability:** It enables LLMs to not just retrieve information but also to use external tools and trigger actions in other systems.\n",
    "*   **Interoperability:** Fosters an ecosystem where different AI tools, models, and data sources can work together more cohesively.\n",
    "\n",
    "MCP aims to break down data silos, making it easier for AI to integrate with real-world applications and enterprise systems, leading to more powerful and context-aware AI solutions.\n",
    "\n",
    "**MCP Typically Follows a Client-Server Architecture:**\n",
    "*   **MCP Hosts/Clients:** Applications (like AI assistants, IDEs, or other AI-powered tools) that want to access data or capabilities. In this demo, this notebook, through LangChain, acts as an MCP client.\n",
    "*   **MCP Servers:** Lightweight programs that expose specific data sources or tools (e.g., a database, an API) through the standardized MCP. The `mcp-server-couchbase` project fulfills this role for Couchbase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "## Get Credentials for OpenAI\n",
    "Please follow the [instructions](https://platform.openai.com/docs/quickstart) to generate the OpenAI credentials.\n",
    "## Create and Deploy Your Free Tier Operational cluster on Capella\n",
    "\n",
    "To get started with Couchbase Capella, create an account and use it to deploy a forever free tier operational cluster. This account provides you with an environment where you can explore and learn about Capella with no time constraint.\n",
    "\n",
    "To learn more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
    "\n",
    "### Couchbase Capella Configuration\n",
    "\n",
    "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
    "\n",
    "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the required bucket (Read and Write) used in the application.\n",
    "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running.\n",
    "* Your Capella free-tier account includes a travel-sample bucket, with sample documents used for booking and travel purposes. You can find more information [here](https://docs.couchbase.com/cloud/get-started/run-first-queries.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "\n",
    "Before running this notebook, ensure you have the following prerequisites met:\n",
    "\n",
    "*   **`mcp-server-couchbase` Project:**\n",
    "    *   Clone the `mcp-server-couchbase` project from [here](https://github.com/Couchbase-Ecosystem/mcp-server-couchbase).\n",
    "    *   You'll need the local path to this project to start the MCP server from this notebook. **Update this path in the `StdioServerParameters` cell later if yours is different.**\n",
    "*   **Set Environment Variables:** This notebook loads the OpenAI API key and other environment variables from the `.env` file. Include the following:\n",
    "\n",
    "    ```\n",
    "    OPENAI_API_KEY=your_openai_api_key_here\n",
    "    CB_CONNECTION_STRING=your_couchbase_connection_string\n",
    "    CB_USERNAME=your_couchbase_username\n",
    "    CB_PASSWORD=your_couchbase_password\n",
    "    CB_BUCKET_NAME=your_target_bucket # e.g., travel-sample\n",
    "    ```\n",
    "\n",
    "    We have already included a `.env.sample` file. Change the file name to `.env` and fill in the environment variables.\n",
    "*   **Setup uv:** uv is a modern and fast python package and project manager. We will use uv to run the MCP server. Install uv from [here](https://docs.astral.sh/uv/getting-started/installation/#installing-uv).\n",
    "*   **Python Libraries:** Install the necessary libraries by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q 'langchain==0.3.25' 'langgraph==0.4.0' 'langchain-openai==0.3.14' 'langchain-mcp-adapters==0.0.9' 'python-dotenv==1.1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "\n",
    "This cell imports the essential Python tools for our project:\n",
    "\n",
    "*   **`dotenv` & `os`:** For loading and using secret API keys and other settings from a `.env` file.\n",
    "*   **`mcp` (ClientSession, StdioServerParameters, stdio_client):** For connecting this notebook (as a client) to the MCP server, which in turn talks to Couchbase.\n",
    "*   **`langchain_mcp_adapters.tools` (`load_mcp_tools`):** To make the Couchbase tools (exposed via MCP) usable by our LangChain AI agent.\n",
    "*   **`langgraph.prebuilt` (`create_react_agent`):** To easily build a \"ReAct\" AI agent that can think and use tools.\n",
    "*   **`langgraph.checkpoint.memory` (`InMemorySaver`):** To help the agent remember past parts of the conversation.\n",
    "*   **`langchain_openai` (`ChatOpenAI`):** To connect to and use OpenAI's language models (like GPT-4).\n",
    "\n",
    "Running this cell makes all these components ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Question-Answering Function\n",
    "\n",
    "This cell defines an asynchronous function `qna(agent)` that we'll use to interact with our ReAct agent.\n",
    "\n",
    "*   It takes the created `agent` as an argument.\n",
    "*   `config = {\"configurable\": {\"thread_id\": \"1\"}}`: This configuration is important for LangGraph agents. It uses a `thread_id` to maintain conversation state. Using the same `thread_id` across multiple calls to the agent allows it to remember previous interactions in that \"thread.\"\n",
    "*   The function then defines a series of example questions (`message`) which we want to ask the agent. The agent queries the Couchbase MCP to get travel related data, formats it and presents it to the user.\n",
    "*   This function allows us to easily test the agent with multiple queries in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def qna(agent):\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "    message = \"Tell me about the database that you are connected to.\"\n",
    "    print(f\"\\n\\n**Running:** {message}\\n\")\n",
    "    result = await agent.ainvoke({\"messages\": message}, config)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    print('-'*50)\n",
    "\n",
    "    message = \"List out the top 5 hotels by the highest aggregate rating?\"\n",
    "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
    "    result = await agent.ainvoke({\"messages\": message}, config)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    print('-'*50)\n",
    "\n",
    "    message = \"Recommend me a flight and hotel from New York to San Francisco\"\n",
    "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
    "    result = await agent.ainvoke({\"messages\": message}, config)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    print('-'*50)\n",
    "\n",
    "    message = \"I'm going to the UK for 1 week. Recommend some great spots to visit for sightseeing. Also mention the respective prices of those places for adults and kids.\"\n",
    "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
    "    result = await agent.ainvoke({\"messages\": message}, config)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    print('-'*50)\n",
    "\n",
    "    message = \"My budget is around 30 pounds a night. What will be the best hotel to stay in?\"\n",
    "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
    "    result = await agent.ainvoke({\"messages\": message}, config)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the System Prompt\n",
    "\n",
    "The system prompt is a crucial piece of instruction given to the Large Language Model (LLM) that powers our agent. It sets the context, defines the agent's persona, capabilities, and constraints.\n",
    "\n",
    "In this system prompt:\n",
    "*   We explain the **Couchbase data hierarchy** (Cluster, Bucket, Scope, Collection, Document) to help the LLM understand how the data is organized.\n",
    "*   We specifically instruct the agent that **\"The data is inside `inventory` scope, so use only that scope.\"** This focuses the agent on the relevant part of the `travel-sample` database.\n",
    "*   We provide **SQL++ query generation guidelines**:\n",
    "    *   \"Any query you generate needs to have only the collection name in the FROM clause.\"\n",
    "    *   \"Every field, collection, scope or bucket name inside the query should be inside backticks.\"\n",
    "*   The overall goal is to guide the LLM to use the provided MCP tools (which will be Couchbase operations) effectively and to formulate correct SQL++ queries for the `inventory` scope.\n",
    "\n",
    "A well-crafted system prompt significantly improves the agent's performance and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Couchbase organizes data with the following hierarchy (from top to bottom):\n",
    "\n",
    "                1. Cluster\n",
    "\n",
    "                The overall container of all Couchbase data and services.\n",
    "\n",
    "                2. Bucket\n",
    "\n",
    "                A bucket is similar to a database in traditional systems.\n",
    "\n",
    "                Each bucket contains multiple scopes.\n",
    "\n",
    "                Example: \"users\", \"analytics\", \"products\"\n",
    "\n",
    "                3. Scope\n",
    "\n",
    "                A scope is a namespace within a bucket that groups collections.\n",
    "\n",
    "                Scopes help isolate data for different microservices or tenants.\n",
    "\n",
    "                Default scope name: _default\n",
    "\n",
    "                4. Collection\n",
    "\n",
    "                The equivalent of a table in relational databases.\n",
    "\n",
    "                Collections store JSON documents.\n",
    "\n",
    "                Default collection name: _default\n",
    "\n",
    "                5. Document\n",
    "\n",
    "                The atomic data unit (usually JSON) stored in a collection.\n",
    "\n",
    "                Each document has a unique key within its collection.\n",
    "\n",
    "                Use the tools to read the database answer questions based on this database.\n",
    "                The data is inside `inventory` scope, so use only that scope.\n",
    "                Any query you generate needs to have only the collection name in the FROM clause.\n",
    "                Every field, collection, scope or bucket name inside the query should be inside backticks.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Language Model and MCP Server\n",
    "\n",
    "This cell sets up two key components:\n",
    "\n",
    "1.  **`model = ChatOpenAI(model=\"gpt-4.1\")`**: This line initializes the LLM we'll be using. We're choosing `gpt-4.1` from OpenAI.\n",
    "2.  **`server_params = StdioServerParameters(...)`**:\n",
    "    *   This configures how our Python script will start and communicate with the `mcp-server-couchbase` application.\n",
    "    *   `command=\"uv\"` and `args=[...]`: This specifies the command to run. Here, it's using `uv run` (a fast Python project and virtual environment manager) to execute the `mcp_server.py` script located in the `mcp-server-couchbase` project directory.\n",
    "        *   **IMPORTANT:** You **MUST** update the `\"--directory\"`, path to point to the correct location of your cloned `mcp-server-couchbase` repository.\n",
    "    *   `env={...}`: This dictionary defines environment variables that will be passed to the MCP server process when it starts. These are crucial for the MCP server to connect to your Couchbase instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1\")\n",
    "\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"uv\",\n",
    "    args=[\n",
    "        \"--directory\",\n",
    "        \"/path/to/mcp-server-couchbase\",\n",
    "        \"run\",\n",
    "        \"src/mcp_server.py\"\n",
    "    ],\n",
    "    env={\n",
    "        \"CB_CONNECTION_STRING\": os.getenv(\"CB_CONNECTION_STRING\"),\n",
    "        \"CB_USERNAME\": os.getenv(\"CB_USERNAME\"),\n",
    "        \"CB_PASSWORD\": os.getenv(\"CB_PASSWORD\"),\n",
    "        \"CB_BUCKET_NAME\": os.getenv(\"CB_BUCKET_NAME\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Main Execution Logic\n",
    "\n",
    "The `main` function ties everything together to set up and run our agent:\n",
    "\n",
    "1.  **Start & Connect to MCP Server:** It first starts the `mcp-server-couchbase` process using `stdio_client` and establishes a communication `ClientSession` with it.\n",
    "2.  **Initialize Session & Load Tools:** The MCP `session` is initialized. Then, `load_mcp_tools` queries the MCP server to get the available Couchbase tools and prepares them for LangChain.\n",
    "3.  **Set Up Agent Memory:** `InMemorySaver` is created to allow the agent to remember conversation history.\n",
    "4.  **Create ReAct Agent:** The `create_react_agent` function builds our AI agent, providing it with the language `model`, the Couchbase `tools`, our `system_prompt`, and the `checkpoint` for memory.\n",
    "5.  **Run Q&A:** Finally, it calls the `qna` function, passing the created `agent` to start the question-and-answer process with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            # Initialize the connection\n",
    "            print(\"Initializing connection...\")\n",
    "            await session.initialize()\n",
    "\n",
    "            # Get tools\n",
    "            print(\"Loading tools...\")\n",
    "            tools = await load_mcp_tools(session)\n",
    "\n",
    "            # Create and run the agent\n",
    "            print(\"Creating agent...\")\n",
    "            checkpoint = InMemorySaver()\n",
    "\n",
    "            agent = create_react_agent(\n",
    "                model, \n",
    "                tools,\n",
    "                prompt=system_prompt,\n",
    "                checkpointer=checkpoint\n",
    "            )\n",
    "\n",
    "            print(\"-\"*25, \"Starting Run\", \"-\"*25)\n",
    "            await qna(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Agent\n",
    "\n",
    "This final cell simply executes the `await main()` function.\n",
    "\n",
    "When you run this cell:\n",
    "1.  The `mcp-server-couchbase` process will be started in the background.\n",
    "2.  The Python script will connect to it as an MCP client.\n",
    "3.  The LangChain ReAct agent will be initialized with the Couchbase tools exposed via MCP.\n",
    "4.  The agent will then attempt to answer the series of questions defined in the `qna` function by:\n",
    "    *   Reasoning about the question.\n",
    "    *   Deciding if a Couchbase tool is needed.\n",
    "    *   Formulating a SQL++ query (if appropriate, based on the system prompt).\n",
    "    *   Executing the tool (which sends the query to the MCP server, which then runs it on Couchbase).\n",
    "    *   Using the tool's output to generate a natural language response.\n",
    "\n",
    "You will see the questions and the agent's answers printed below. This demonstrates the end-to-end flow of a natural language query being translated into database actions and then into a user-friendly response, all orchestrated by the LangChain agent using MCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing connection...\n",
      "Loading tools...\n",
      "Creating agent...\n",
      "------------------------- Starting Run -------------------------\n",
      "\n",
      "\n",
      "**Running:** Tell me about the database that you are connected to.\n",
      "\n",
      "I am connected to a Couchbase database that contains several scopes and collections. The main scope relevant for queries is inventory. Within the inventory scope, there are the following collections:\n",
      "\n",
      "- cache\n",
      "- route\n",
      "- landmark\n",
      "- hotel\n",
      "- airport\n",
      "- airline\n",
      "\n",
      "Each collection contains documents (typically in JSON format), and you can query or retrieve data from these collections as needed. The structure is as follows:\n",
      "\n",
      "Cluster → Bucket → Scope (inventory) → Collection (cache, route, landmark, hotel, airport, airline) → Document\n",
      "\n",
      "Let me know if you want details about any specific collection or want to see the data or schema from any of them.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "**Running**: List out the top 5 hotels by the highest aggregate rating?\n",
      "\n",
      "The top 5 hotels by highest aggregate (average) overall rating are:\n",
      "\n",
      "1. InterContinental The Clement Monterey\n",
      "2. Hotel Bijou\n",
      "3. DoubleTree by Hilton Hotel London—Westminster\n",
      "4. Stanford Court Hotel\n",
      "5. Beaumont Estate\n",
      "\n",
      "All of these hotels have an average overall rating of 5 based on their review data.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "**Running**: Recommend me a flight and hotel from New York to San Francisco\n",
      "\n",
      "Here are some recommendations based on your request for a flight and hotel from New York to San Francisco:\n",
      "\n",
      "Flights (Airlines operating United States domestic routes):\n",
      "- Delta Air Lines (IATA: DL)\n",
      "- American Airlines (IATA: AA)\n",
      "- United Airlines (IATA: UA)\n",
      "\n",
      "Main airports:\n",
      "- New York: John F Kennedy Intl (JFK), La Guardia (LGA), and others\n",
      "- San Francisco: San Francisco Intl (SFO)\n",
      "\n",
      "Hotels in San Francisco:\n",
      "- I was unable to retrieve the top-rated hotel due to a technical issue. Would you like a list of the most highly-rated hotels, or a random well-rated hotel in San Francisco instead?\n",
      "\n",
      "Let me know if you'd like more specific flight suggestions (such as direct routes or times) or details about available hotels.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "**Running**: I'm going to the UK for 1 week. Recommend some great spots to visit for sightseeing. Also mention the respective prices of those places for adults and kids.\n",
      "\n",
      "Here are some great sightseeing spots you can visit in the UK, along with their prices for adults and kids (where available):\n",
      "\n",
      "1. Glasgow Cathedral (Glasgow)\n",
      "   - Price: Free for all ages\n",
      "\n",
      "2. City Chambers (Glasgow)\n",
      "   - Price: Free for all ages\n",
      "\n",
      "3. St Enoch Subway Station (Glasgow)\n",
      "   - Price: Free for all ages\n",
      "\n",
      "4. Royal Engineers Museum (Gillingham, Kent)\n",
      "   - Price: Not listed (usually museums in the UK might charge around £6-£12 for adults, often discounts for kids or free for children under a certain age—please check the official site)\n",
      "\n",
      "While some popular spots like museums and historic cathedrals have free entry, others (such as certain tours or special exhibits) may charge fees. It’s a good idea to check online or at each location for exact pricing based on current exhibitions and age groups.\n",
      "\n",
      "If you’d like recommendations for other iconic places across the UK (such as London Eye, Tower of London, Stonehenge, etc.) and their specific prices, let me know!\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "**Running**: My budget is around 30 pounds a night. What will be the best hotel to stay in?\n",
      "\n",
      "Here are some good hotel options in the UK for a budget of around £30 per night:\n",
      "\n",
      "1. The Wellington (London)\n",
      "   - Price: From £30 per night (includes simple breakfast, internet access)\n",
      "   - Description: Located in a quiet area, 10 min from Victoria Station.\n",
      "\n",
      "2. Rooms Inn (Newcastle upon Tyne)\n",
      "   - Price: Double £30–£85 (breakfast extra)\n",
      "   - Description: Basic hotel in a residential area.\n",
      "\n",
      "Geufron Hall B&B (Llangollen) is highly rated but starts at £50, above your target budget. The Park Tower Knightsbridge Hotel and Novotel London West are much higher than £30 per night.\n",
      "\n",
      "Among these, The Wellington in London is likely your best value option at exactly your budget and with a central London location.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
