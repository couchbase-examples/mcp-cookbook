{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain ReAct Agent with Couchbase via Model Context Protocol (MCP) - A Tutorial\n",
    "\n",
    "This notebook demonstrates how to build a ReAct (Reasoning and Acting) agent using [LangChain](https://www.langchain.com/) and [LangGraph](https://www.langchain.com/langgraph) that can interact with a Couchbase database. The key to this interaction is the Model Context Protocol (MCP), which allows the AI agent to seamlessly connect to and use Couchbase as a tool.\n",
    "\n",
    "## What is the Model Context Protocol (MCP)?\n",
    "\n",
    "The [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard designed to standardize how AI assistants and applications connect to and interact with external data sources, tools, and systems. Think of MCP as a universal adapter that allows AI models to seamlessly access the context they need to produce more relevant, accurate, and actionable responses.\n",
    "\n",
    "**Key Goals and Features of MCP:**\n",
    "\n",
    "*   **Standardized Communication:** MCP provides a common language and structure for AI models to communicate with diverse backend systems, replacing the need for numerous custom integrations.\n",
    "*   **Enhanced Context Management:** It helps manage the limited context windows of LLMs efficiently, enabling them to maintain longer, more coherent interactions and leverage historical data.\n",
    "*   **Secure Data Access:** MCP emphasizes secure connections, allowing developers to expose data through MCP servers while maintaining control over their infrastructure.\n",
    "*   **Tool Use and Actionability:** It enables LLMs to not just retrieve information but also to use external tools and trigger actions in other systems.\n",
    "*   **Interoperability:** Fosters an ecosystem where different AI tools, models, and data sources can work together more cohesively.\n",
    "\n",
    "MCP aims to break down data silos, making it easier for AI to integrate with real-world applications and enterprise systems, leading to more powerful and context-aware AI solutions.\n",
    "\n",
    "**MCP Typically Follows a Client-Server Architecture:**\n",
    "*   **MCP Hosts/Clients:** Applications (like AI assistants, IDEs, or other AI-powered tools) that want to access data or capabilities. In this demo, this notebook, through LangChain, acts as an MCP client.\n",
    "*   **MCP Servers:** Lightweight programs that expose specific data sources or tools (e.g., a database, an API) through the standardized MCP. The `mcp-server-couchbase` project fulfills this role for Couchbase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "## Get Credentials for OpenAI\n",
    "Please follow the [instructions](https://platform.openai.com/docs/quickstart) to generate the OpenAI credentials.\n",
    "## Create and Deploy Your Free Tier Operational cluster on Capella\n",
    "\n",
    "To get started with Couchbase Capella, create an account and use it to deploy a forever free tier operational cluster. This account provides you with an environment where you can explore and learn about Capella with no time constraint.\n",
    "\n",
    "To learn more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
    "\n",
    "### Couchbase Capella Configuration\n",
    "\n",
    "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
    "\n",
    "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the required bucket (Read and Write) used in the application.\n",
    "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running.\n",
    "* Your Capella free-tier account includes a travel-sample bucket, with sample documents used for booking and travel purposes. You can find more information [here](https://docs.couchbase.com/cloud/get-started/run-first-queries.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "\n",
    "Before running this notebook, ensure you have the following prerequisites met:\n",
    "\n",
    "*   **`mcp-server-couchbase` Project:**\n",
    "    *   Clone the `mcp-server-couchbase` project from [here](https://github.com/Couchbase-Ecosystem/mcp-server-couchbase).\n",
    "    *   You'll need the local path to this project to start the MCP server from this notebook. **Update this path in the `StdioServerParameters` cell later if yours is different.**\n",
    "*   **Set Environment Variables:** This notebook loads the OpenAI API key and other environment variables from the `.env` file. Include the following:\n",
    "    ```env\n",
    "    OPENAI_API_KEY=your_openai_api_key_here\n",
    "    CB_CONNECTION_STRING=your_couchbase_connection_string\n",
    "    CB_USERNAME=your_couchbase_username\n",
    "    CB_PASSWORD=your_couchbase_password\n",
    "    CB_BUCKET_NAME=your_target_bucket # e.g., travel-sample\n",
    "    ```\n",
    "    We have already included a `.env.sample` file. Change the file name to `.env` and fill in the environment variables.\n",
    "*   **Setup uv:** uv is a modern and fast python package and project manager. We will use uv to run the MCP server. Install uv from [here](https://docs.astral.sh/uv/getting-started/installation/#installing-uv).\n",
    "*   **Python Libraries:** Install the necessary libraries by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q 'langchain==0.3.25' 'langgraph==0.4.0' 'langchain-openai==0.3.14' 'langchain-mcp-adapters==0.0.9' 'python-dotenv==1.1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "\n",
    "This cell imports the essential Python tools for our project:\n",
    "\n",
    "*   **`dotenv` & `os`:** For loading and using secret API keys and other settings from a `.env` file.\n",
    "*   **`mcp` (ClientSession, StdioServerParameters, stdio_client):** For connecting this notebook (as a client) to the MCP server, which in turn talks to Couchbase.\n",
    "*   **`langchain_mcp_adapters.tools` (`load_mcp_tools`):** To make the Couchbase tools (exposed via MCP) usable by our LangChain AI agent.\n",
    "*   **`langgraph.prebuilt` (`create_react_agent`):** To easily build a \"ReAct\" AI agent that can think and use tools.\n",
    "*   **`langgraph.checkpoint.memory` (`InMemorySaver`):** To help the agent remember past parts of the conversation.\n",
    "*   **`langchain_openai` (`ChatOpenAI`):** To connect to and use OpenAI's language models (like GPT-4).\n",
    "\n",
    "Running this cell makes all these components ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Question-Answering Function\n",
    "\n",
    "This cell defines an asynchronous function `qna(agent)` that we'll use to interact with our ReAct agent.\n",
    "\n",
    "*   It takes the created `agent` as an argument.\n",
    "*   `config = {\"configurable\": {\"thread_id\": \"1\"}}`: This configuration is important for LangGraph agents. It uses a `thread_id` to maintain conversation state. Using the same `thread_id` across multiple calls to the agent allows it to remember previous interactions in that \"thread.\"\n",
    "*   The function then defines a series of example questions (`message`) which we want to ask the agent. The agent queries the Couchbase MCP to get travel related data, formats it and presents it to the user.\n",
    "*   This function allows us to easily test the agent with multiple queries in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def qna(agent):\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "    message = \"Tell me about the database that you are connected to.\"\n",
    "    print(f\"\\n\\n**Running:** {message}\\n\")\n",
    "    result = await agent.ainvoke({\"messages\": message}, config)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    print('-'*50)\n",
    "\n",
    "    message = \"List out the top 5 hotels by the highest aggregate rating?\"\n",
    "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
    "    result = await agent.ainvoke({\"messages\": message}, config)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    print('-'*50)\n",
    "\n",
    "    message = \"Recommend me a flight and hotel from New York to San Francisco\"\n",
    "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
    "    result = await agent.ainvoke({\"messages\": message}, config)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    print('-'*50)\n",
    "\n",
    "    message = \"I'm going to the UK for 1 week. Recommend some great spots to visit for sightseeing. Also mention the respective prices of those places for adults and kids.\"\n",
    "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
    "    result = await agent.ainvoke({\"messages\": message}, config)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    print('-'*50)\n",
    "\n",
    "    message = \"My budget is around 30 pounds a night. What will be the best hotel to stay in?\"\n",
    "    print(f\"\\n\\n**Running**: {message}\\n\")\n",
    "    result = await agent.ainvoke({\"messages\": message}, config)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the System Prompt\n",
    "\n",
    "The system prompt is a crucial piece of instruction given to the Large Language Model (LLM) that powers our agent. It sets the context, defines the agent's persona, capabilities, and constraints.\n",
    "\n",
    "In this system prompt:\n",
    "*   We explain the **Couchbase data hierarchy** (Cluster, Bucket, Scope, Collection, Document) to help the LLM understand how the data is organized.\n",
    "*   We specifically instruct the agent that **\"The data is inside `inventory` scope, so use only that scope.\"** This focuses the agent on the relevant part of the `travel-sample` database.\n",
    "*   We provide **SQL++ query generation guidelines**:\n",
    "    *   \"Any query you generate needs to have only the collection name in the FROM clause.\"\n",
    "    *   \"Every field, collection, scope or bucket name inside the query should be inside backticks.\"\n",
    "*   The overall goal is to guide the LLM to use the provided MCP tools (which will be Couchbase operations) effectively and to formulate correct SQL++ queries for the `inventory` scope.\n",
    "\n",
    "A well-crafted system prompt significantly improves the agent's performance and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Couchbase organizes data with the following hierarchy (from top to bottom):\n",
    "\n",
    "                1. Cluster\n",
    "\n",
    "                The overall container of all Couchbase data and services.\n",
    "\n",
    "                2. Bucket\n",
    "\n",
    "                A bucket is similar to a database in traditional systems.\n",
    "\n",
    "                Each bucket contains multiple scopes.\n",
    "\n",
    "                Example: \"users\", \"analytics\", \"products\"\n",
    "\n",
    "                3. Scope\n",
    "\n",
    "                A scope is a namespace within a bucket that groups collections.\n",
    "\n",
    "                Scopes help isolate data for different microservices or tenants.\n",
    "\n",
    "                Default scope name: _default\n",
    "\n",
    "                4. Collection\n",
    "\n",
    "                The equivalent of a table in relational databases.\n",
    "\n",
    "                Collections store JSON documents.\n",
    "\n",
    "                Default collection name: _default\n",
    "\n",
    "                5. Document\n",
    "\n",
    "                The atomic data unit (usually JSON) stored in a collection.\n",
    "\n",
    "                Each document has a unique key within its collection.\n",
    "\n",
    "                Use the tools to read the database answer questions based on this database.\n",
    "                The data is inside `inventory` scope, so use only that scope.\n",
    "                Any query you generate needs to have only the collection name in the FROM clause.\n",
    "                Every field, collection, scope or bucket name inside the query should be inside backticks.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Language Model and MCP Server\n",
    "\n",
    "This cell sets up two key components:\n",
    "\n",
    "1.  **`model = ChatOpenAI(model=\"gpt-4.1\")`**: This line initializes the LLM we'll be using. We're choosing `gpt-4.1` from OpenAI.\n",
    "2.  **`server_params = StdioServerParameters(...)`**:\n",
    "    *   This configures how our Python script will start and communicate with the `mcp-server-couchbase` application.\n",
    "    *   `command=\"uv\"` and `args=[...]`: This specifies the command to run. Here, it's using `uv run` (a fast Python project and virtual environment manager) to execute the `mcp_server.py` script located in the `mcp-server-couchbase` project directory.\n",
    "        *   **IMPORTANT:** You **MUST** update the `\"--directory\"`, path to point to the correct location of your cloned `mcp-server-couchbase` repository.\n",
    "    *   `env={...}`: This dictionary defines environment variables that will be passed to the MCP server process when it starts. These are crucial for the MCP server to connect to your Couchbase instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1\")\n",
    "\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"uv\",\n",
    "    args=[\n",
    "        \"--directory\",\n",
    "        \"/path/to/mcp-server-couchbase\",\n",
    "        \"run\",\n",
    "        \"src/mcp_server.py\"\n",
    "    ],\n",
    "    env={\n",
    "        \"CB_CONNECTION_STRING\": os.getenv(\"CB_CONNECTION_STRING\"),\n",
    "        \"CB_USERNAME\": os.getenv(\"CB_USERNAME\"),\n",
    "        \"CB_PASSWORD\": os.getenv(\"CB_PASSWORD\"),\n",
    "        \"CB_BUCKET_NAME\": os.getenv(\"CB_BUCKET_NAME\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Main Execution Logic\n",
    "\n",
    "The `main` function ties everything together to set up and run our agent:\n",
    "\n",
    "1.  **Start & Connect to MCP Server:** It first starts the `mcp-server-couchbase` process using `stdio_client` and establishes a communication `ClientSession` with it.\n",
    "2.  **Initialize Session & Load Tools:** The MCP `session` is initialized. Then, `load_mcp_tools` queries the MCP server to get the available Couchbase tools and prepares them for LangChain.\n",
    "3.  **Set Up Agent Memory:** `InMemorySaver` is created to allow the agent to remember conversation history.\n",
    "4.  **Create ReAct Agent:** The `create_react_agent` function builds our AI agent, providing it with the language `model`, the Couchbase `tools`, our `system_prompt`, and the `checkpoint` for memory.\n",
    "5.  **Run Q&A:** Finally, it calls the `qna` function, passing the created `agent` to start the question-and-answer process with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            # Initialize the connection\n",
    "            print(\"Initializing connection...\")\n",
    "            await session.initialize()\n",
    "\n",
    "            # Get tools\n",
    "            print(\"Loading tools...\")\n",
    "            tools = await load_mcp_tools(session)\n",
    "\n",
    "            # Create and run the agent\n",
    "            print(\"Creating agent...\")\n",
    "            checkpoint = InMemorySaver()\n",
    "\n",
    "            agent = create_react_agent(\n",
    "                model, \n",
    "                tools,\n",
    "                prompt=system_prompt,\n",
    "                checkpointer=checkpoint\n",
    "            )\n",
    "\n",
    "            print(\"-\"*25, \"Starting Run\", \"-\"*25)\n",
    "            await qna(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Agent\n",
    "\n",
    "This final cell simply executes the `await main()` function.\n",
    "\n",
    "When you run this cell:\n",
    "1.  The `mcp-server-couchbase` process will be started in the background.\n",
    "2.  The Python script will connect to it as an MCP client.\n",
    "3.  The LangChain ReAct agent will be initialized with the Couchbase tools exposed via MCP.\n",
    "4.  The agent will then attempt to answer the series of questions defined in the `qna` function by:\n",
    "    *   Reasoning about the question.\n",
    "    *   Deciding if a Couchbase tool is needed.\n",
    "    *   Formulating a SQL++ query (if appropriate, based on the system prompt).\n",
    "    *   Executing the tool (which sends the query to the MCP server, which then runs it on Couchbase).\n",
    "    *   Using the tool's output to generate a natural language response.\n",
    "\n",
    "You will see the questions and the agent's answers printed below. This demonstrates the end-to-end flow of a natural language query being translated into database actions and then into a user-friendly response, all orchestrated by the LangChain agent using MCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing connection...\n",
      "Loading tools...\n",
      "Creating agent...\n",
      "------------------------- Starting Run -------------------------\n",
      "\n",
      "\n",
      "**Running:** Tell me about the database that you are connected to.\n",
      "\n",
      "I am connected to a Couchbase database that contains multiple scopes and collections. Here’s an overview:\n",
      "\n",
      "- The main bucket contains several scopes. The most prominent one for data access is inventory.\n",
      "- The inventory scope contains the following collections: cache, route, landmark, hotel, airport, and airline.\n",
      "\n",
      "Each collection organizes related types of documents, for example:\n",
      "- hotel: Likely stores hotel information.\n",
      "- route: Likely stores travel routes.\n",
      "- airport: Likely stores airport data.\n",
      "- airline: Likely stores airline information.\n",
      "- landmark: Likely stores famous places or points of interest.\n",
      "- cache: Possibly used for temporary or fast-access data.\n",
      "\n",
      "I can only answer questions and query data from the inventory scope and these collections. If you need details or queries from specific collections, let me know!\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "**Running**: List out the top 5 hotels by the highest aggregate rating?\n",
      "\n",
      "The top 5 hotels by the highest aggregate (average) rating are:\n",
      "\n",
      "1. Hôtel Acacias Etoile\n",
      "2. Corran House\n",
      "3. Travelodge Derry Hotel\n",
      "4. Hotel del Sol\n",
      "5. The LA Hotel Downtown\n",
      "\n",
      "All these hotels have an average overall review rating of 5.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "**Running**: Recommend me a flight and hotel from New York to San Francisco\n",
      "\n",
      "Here is a recommended flight and hotel for your trip from New York to San Francisco:\n",
      "\n",
      "Hotel Recommendation (San Francisco):\n",
      "- Inn on Castro\n",
      "- Address: 321 Castro St\n",
      "- Description: An upscale bed and breakfast in a restored house.\n",
      "\n",
      "Flight Recommendation (New York to San Francisco):\n",
      "- Origin City: New York (JFK)\n",
      "- Destination City: San Francisco (SFO)\n",
      "- Airline: AS (Alaska Airlines)\n",
      "- Example Flight: AS717 (Departs at 01:41 UTC), Non-stop\n",
      "- Distance: Approximately 4152 km\n",
      "\n",
      "Let me know if you need details on other hotels or specific flight schedules!\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "**Running**: I'm going to the UK for 1 week. Recommend some great spots to visit for sightseeing. Also mention the respective prices of those places for adults and kids.\n",
      "\n",
      "I am gathering a list of great sightseeing spots in the UK, along with their descriptions and prices for adults and kids (when available).\n",
      "\n",
      "Please wait a moment while I compile the recommendations for you.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "**Running**: My budget is around 30 pounds a night. What will be the best hotel to stay in?\n",
      "\n",
      "Based on your budget of around £30 a night, here are some of the best hotel options in the United Kingdom:\n",
      "\n",
      "1. Glencoe Youth Hostel, Highland\n",
      "   - Price: £17.00 per night\n",
      "   - Description: 62 Family Bunk Rooms.\n",
      "\n",
      "2. Rhossili Bunkhouse, Swansea\n",
      "   - Price: From £15 per night per person\n",
      "   - Description: Within easy walking distance of three beaches, great for groups of friends or families.\n",
      "\n",
      "3. Once Brewed YHA Hostel, Northumberland\n",
      "   - Price: Beds from £16 per night\n",
      "   - Description: A pleasant and friendly hostel.\n",
      "\n",
      "4. The Greenhead Hotel and Hostel, Greenhead\n",
      "   - Price: Hostel (£15 per person per night)\n",
      "   - Description: Both hotel and hostel options, located near Hadrian’s Wall.\n",
      "\n",
      "All these options are well within your budget and located in scenic or convenient areas for travelers. Let me know if you would like details on any specific location!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
